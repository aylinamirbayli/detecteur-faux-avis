---
title: "analyse de donnée"
author: "AMIRBAYLI Aylin"
date: "2026-01-03"
output: html_document
---

```{r setup, message=FALSE, warning=FALSE}
library(tm)
```


```{r}
data <- read.csv("data/raw/fake_reviews_dataset.csv")
head(data)
```

```{r}
str(data)
```
```{r}
table(data$label)
```

Le jeu de données est équilibré entre avis authentiques et avis frauduleux, ce qui permet un entraînement équitable du modèle.

```{r}
# Exemple d'un avis authentique
data[data$label == "CG", "text_"][1]

# Exemple d'un avis faux
data[data$label == "OR", "text_"][1]
```

Les avis frauduleux ont tendance à utiliser un vocabulaire très positif, générique et peu informatif.



```{r}
# Créer un corpus de texte
corpus <- VCorpus(VectorSource(data$text_))

# Nettoyage du texte
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)

# Vérifier le résultat sur un texte
as.character(corpus[[1]])
```
```{r}
# Créer la matrice documents-termes
dtm <- DocumentTermMatrix(corpus)

# Aperçu
dtm
```

```{r}
# Enlever les mots trop rares (garder ceux présents dans au moins 1% des avis)
dtm2 <- removeSparseTerms(dtm, 0.99)

dtm2
```
```{r}
# Variable cible binaire
y <- ifelse(data$label == "OR", 1, 0)

# Vérification
table(y)
```
```{r}
# Conversion de la matrice documents-termes en data frame
X <- as.data.frame(as.matrix(dtm2))

# Vérification des dimensions
dim(X)
```

```{r}
set.seed(123)  # pour la reproductibilité

n <- nrow(X)
train_index <- sample(1:n, size = 0.8 * n)

X_train <- X[train_index, ]
X_test  <- X[-train_index, ]

y_train <- y[train_index]
y_test  <- y[-train_index]

# Vérification
dim(X_train)
dim(X_test)
```

```{r}
# Modèle de régression logistique
modele_logit <- glm(
  y_train ~ .,
  data = X_train,
  family = binomial
)
```

```{r}
proba_test <- predict(modele_logit, X_test, type = "response")
y_pred <- ifelse(proba_test > 0.5, 1, 0)
```

```{r}
table(Prediction = y_pred, Réel = y_test)
```

```{r}
mean(y_pred == y_test)
```

Le modèle de régression logistique permet de détecter les faux avis avec une accuracy de 81,6 %. Il identifie correctement une grande partie des avis frauduleux tout en maintenant une bonne capacité à reconnaître les avis authentiques.

```{r}
table(Prediction = y_pred, Réel = y_test)
```

```{r}
cm <- table(Prediction = y_pred, Reel = y_test)

TP <- cm["1","1"]
TN <- cm["0","0"]
FP <- cm["1","0"]
FN <- cm["0","1"]

precision <- TP / (TP + FP)
recall    <- TP / (TP + FN)
f1        <- 2 * precision * recall / (precision + recall)
accuracy  <- mean(y_pred == y_test)

data.frame(accuracy, precision, recall, f1)
```
Sur l’échantillon test, la régression logistique atteint une accuracy de 0,816, ce qui signifie que 81,6 % des avis sont correctement classés (vrai vs faux). La precision = 0,806 indique que, parmi les avis prédits comme faux, environ 80,6 % sont réellement faux (donc ~19,4 % sont des faux positifs). Le recall = 0,830 montre que le modèle détecte environ 83 % des faux avis (donc ~17 % échappent à la détection). Le F1-score = 0,818 confirme un bon compromis entre la capacité à repérer les avis frauduleux et la limitation des erreurs de classification.

```{r}
# --- Fonction de prédiction (option A : logit) ---
predire_avis <- function(texte, modele, dtm_ref, seuil = 0.5) {

  # 1) Nettoyage texte (même pipeline que l'entraînement)
  corp_new <- VCorpus(VectorSource(texte))
  corp_new <- tm_map(corp_new, content_transformer(tolower))
  corp_new <- tm_map(corp_new, removePunctuation)
  corp_new <- tm_map(corp_new, removeNumbers)
  corp_new <- tm_map(corp_new, removeWords, stopwords("english"))
  corp_new <- tm_map(corp_new, stripWhitespace)

  # 2) DTM du nouveau texte avec EXACTEMENT le même vocabulaire que l'entraînement
  dtm_new <- DocumentTermMatrix(corp_new, control = list(dictionary = Terms(dtm_ref)))

  # 3) Passage en data.frame (mêmes colonnes)
  x_new <- as.data.frame(as.matrix(dtm_new))

  # 4) Proba + classe
  proba_fake <- predict(modele, newdata = x_new, type = "response")
  classe <- ifelse(proba_fake >= seuil, 1, 0)

  list(
    proba_fake = as.numeric(proba_fake),
    prediction = ifelse(classe == 1, "FAUX (OR)", "VRAI (CG)")
  )
}

```

```{r}
set.seed(1)
ex_vrai <- data[data$label == "CG", "text_"][1]
ex_faux <- data[data$label == "OR", "text_"][1]

predire_avis(ex_vrai, modele_logit, dtm2)
predire_avis(ex_faux, modele_logit, dtm2)
```
Le modèle renvoie une probabilité d’être faux (OR). Si cette probabilité dépasse 0,5, on classe l’avis comme faux ; sinon, on le classe comme authentique. Ici, l’avis CG a une probabilité faible (0,15) donc il est classé authentique, alors que l’avis OR a une probabilité élevée (0,77) donc il est classé faux.

```{r}
# Coefficients du modèle
coef_mod <- coef(modele_logit)

# On enlève l'intercept
coef_mod <- coef_mod[names(coef_mod) != "(Intercept)"]

# Top mots qui augmentent la proba d'être FAUX (OR)
top_fake <- sort(coef_mod, decreasing = TRUE)[1:20]

# Top mots qui augmentent la proba d'être VRAI (CG) (coeff négatifs)
top_vrai <- sort(coef_mod, decreasing = FALSE)[1:20]

top_fake
top_vrai
```
Les coefficients montrent quels mots poussent le modèle vers FAUX (OR) ou VRAI (CG) :
coefficients positifs → augmentent la probabilité d’un avis faux (mots plutôt vagues/nuancés comme maybe, however, instead).
coefficients négatifs → augmentent la probabilité d’un avis authentique (mots plus concrets liés au produit comme sturdy, instructions, plastic).
Donc le modèle distingue surtout vocabulaire générique vs détails spécifiques.

```{r}
texte_test <- "This product is amazing, I recommend it to everyone!!!"
predire_avis(texte_test, modele_logit, dtm2)
```

Conclusion
Dans ce projet, nous avons cherché à déterminer s’il est possible de détecter automatiquement les avis faux à partir du contenu textuel.
À l’aide de techniques de traitement automatique du langage (NLP) et d’un modèle de régression logistique, nous avons transformé les avis en variables numériques (matrice documents-termes), puis entraîné un classifieur capable de distinguer avis authentiques (CG) et avis faux (OR).
Les résultats montrent que le modèle obtient de bonnes performances (accuracy ≈ 82 %, F1-score ≈ 0,82), ce qui indique qu’une grande partie des avis peut être correctement classée uniquement à partir du texte.
L’analyse des coefficients met en évidence que les avis faux utilisent davantage un vocabulaire vague et générique, tandis que les avis authentiques contiennent plus de détails concrets liés au produit.
Ce projet illustre ainsi comment des méthodes simples de NLP peuvent contribuer à la lutte contre les avis trompeurs, avec des applications concrètes pour les plateformes en ligne, les entreprises et les consommateurs.
Des améliorations futures pourraient inclure des modèles plus avancés (TF-IDF, modèles pénalisés ou méthodes de deep learning) afin d’augmenter encore la précision du système.

```{r}
saveRDS(modele_logit, "results/modele_logit.rds")
saveRDS(dtm2, "results/dtm_ref.rds")
```

